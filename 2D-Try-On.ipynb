{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from transformers import SamModel, SamProcessor\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def get_shoulder_coordinates(image_path):\n",
    "    # Initialize MediaPipe Pose\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not load image.\")\n",
    "        return None\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        height, width, _ = image.shape\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        # Extract left and right shoulder coordinates (landmarks 11 and 12)\n",
    "        left_shoulder = (int(landmarks[11].x * width), int(landmarks[11].y * height))\n",
    "        right_shoulder = (int(landmarks[12].x * width), int(landmarks[12].y * height))\n",
    "\n",
    "        return left_shoulder, right_shoulder\n",
    "    else:\n",
    "        print(\"No pose detected in the image.\")\n",
    "        return None\n",
    "\n",
    "image_path = \"/content/drive/MyDrive/Try On/Harsh.jpg\"  # Change this to your image file path\n",
    "coordinates = get_shoulder_coordinates(image_path)\n",
    "\n",
    "# Load original image\n",
    "img = load_image(image_path)\n",
    "\n",
    "# Load new t-shirt image (ensure it has a transparent background)\n",
    "new_tshirt = load_image(\"/content/drive/MyDrive/Try On/Garment-1.png\")\n",
    "\n",
    "# Load model and processor\n",
    "model = SamModel.from_pretrained(\"Zigeng/SlimSAM-uniform-50\").to(\"cuda\")\n",
    "processor = SamProcessor.from_pretrained(\"Zigeng/SlimSAM-uniform-50\")\n",
    "\n",
    "# Define input points for segmentation (adjust as needed)\n",
    "left_shoulder, right_shoulder = coordinates\n",
    "input_points = [[[left_shoulder[0], left_shoulder[1]], [right_shoulder[0], right_shoulder[1]]]]\n",
    "\n",
    "inputs = processor(img, input_points=input_points, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Process mask\n",
    "masks = processor.image_processor.post_process_masks(outputs.pred_masks.cpu(),\n",
    "                                                      inputs[\"original_sizes\"].cpu(),\n",
    "                                                      inputs[\"reshaped_input_sizes\"].cpu())\n",
    "\n",
    "# Convert mask to PIL image\n",
    "mask_tensor = masks[0][0][2].to(dtype=torch.uint8)\n",
    "mask = transforms.ToPILImage()(mask_tensor * 255)\n",
    "\n",
    "# Resize new t-shirt to match the original image\n",
    "new_tshirt = new_tshirt.resize(img.size, Image.LANCZOS)\n",
    "\n",
    "# Paste new t-shirt onto the original image using the mask\n",
    "img_with_new_tshirt = Image.composite(new_tshirt, img, mask)\n",
    "\n",
    "# Display results\n",
    "make_image_grid([img, mask, img_with_new_tshirt], cols=3, rows=1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
